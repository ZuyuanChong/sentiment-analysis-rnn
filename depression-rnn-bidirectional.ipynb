{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoRp3XtIx4j8",
        "outputId": "8d89008e-5e0e-4b81-80eb-6819cbf96443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVOA24701iTU",
        "outputId": "91224a65-88df-442b-d9e0-7ce0fd3a572c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmoRf88Kx4kD",
        "outputId": "1c1a85e7-1ca9-4b59-8566-a5126b3b4e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2022.5.18.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xLetcTBIx4kH",
        "outputId": "9da53af8-879a-4557-9f62-a827a8863cdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import spacy \n",
        "\n",
        "spacy.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dG38OUDx4kL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext import datasets\n",
        "from torchtext import data\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "2mzb7hXKx4kQ",
        "outputId": "93cb54f6-3217-47c1-e309-868dc3f2c490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  condition\n",
              "0  My 7th year in that school (13years old) was g...        0.0\n",
              "1      “Clash of the titans!” Caw exclaimed happily.        0.0\n",
              "2                                         I hate it.        1.0\n",
              "3  Starving because I just couldn't leave the saf...        1.0\n",
              "4  ](http://www.esquire.com/news-politics/a23772/...        0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3de5c58-48bd-490a-901d-2865e143e016\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My 7th year in that school (13years old) was g...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Clash of the titans!” Caw exclaimed happily.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I hate it.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Starving because I just couldn't leave the saf...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>](http://www.esquire.com/news-politics/a23772/...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3de5c58-48bd-490a-901d-2865e143e016')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3de5c58-48bd-490a-901d-2865e143e016 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3de5c58-48bd-490a-901d-2865e143e016');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tweets = pd.read_csv('/content/drive/My Drive/depressionrnn/all_nobias.csv', error_bad_lines = False)\n",
        "\n",
        "tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RCb31pkd2ECf",
        "outputId": "6d426e0b-81ea-4489-f22b-341a1aa8ad51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       SentimentText  Sentiment\n",
              "0  My 7th year in that school (13years old) was g...        0.0\n",
              "1      “Clash of the titans!” Caw exclaimed happily.        0.0\n",
              "2                                         I hate it.        1.0\n",
              "3  Starving because I just couldn't leave the saf...        1.0\n",
              "4  ](http://www.esquire.com/news-politics/a23772/...        0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f281dc3-f136-400f-8d09-c910fb4114c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My 7th year in that school (13years old) was g...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Clash of the titans!” Caw exclaimed happily.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I hate it.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Starving because I just couldn't leave the saf...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>](http://www.esquire.com/news-politics/a23772/...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f281dc3-f136-400f-8d09-c910fb4114c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f281dc3-f136-400f-8d09-c910fb4114c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f281dc3-f136-400f-8d09-c910fb4114c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tweets = tweets.rename(index = str, columns = {'sentence': 'SentimentText', 'condition': 'Sentiment'})\n",
        "\n",
        "tweets.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUwa5k7lhVCp"
      },
      "outputs": [],
      "source": [
        "tweets=tweets.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5EOmg0Ox4kV"
      },
      "source": [
        "The dataframe consists of 4 columns and we want to use only ‘Sentiment’ and ‘SentimentText’."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jFTyrxYx4ka",
        "outputId": "6ca981ce-8c48-4e4a-9c1b-6dd25daabbf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5731, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tweets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJU5RB4-x4ke",
        "outputId": "f1573d62-4167-4766-fd2b-1e35fdc2eaf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tweets['Sentiment'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJZwLFefx4ki",
        "outputId": "a3481531-ceda-40be-e457-c109844808f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    3904\n",
              "1.0    1827\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tweets.Sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "RaPiBGVWx4kl",
        "outputId": "94baaf16-1119-48b3-e2b1-3f7d7926bc33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.5, 0, 'Labels')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "\n",
        "ax = sns.barplot(x=tweets.Sentiment.unique(), y=tweets.Sentiment.value_counts())\n",
        "\n",
        "ax.set(xlabel='Labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRv0G_Vcx4kp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(tweets, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq4YwB1gx4kt",
        "outputId": "40b6dee9-eb0e-4b54-fca7-1e7d5d4d943c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                          SentimentText  Sentiment\n",
              " 0     I keep trying and scrambling to pull myself ou...        0.0\n",
              " 1     She messages me in the morning and says I'm co...        1.0\n",
              " 2     “Let’s see, twentieth century Sol...” she muse...        0.0\n",
              " 3     He could feel the eyes of the marines under hi...        0.0\n",
              " 4     “The whole point of this excursion was to prov...        0.0\n",
              " ...                                                 ...        ...\n",
              " 4579                                        They cheat.        0.0\n",
              " 4580  My boyfriend is the most amazing person I've e...        0.0\n",
              " 4581  But its the only thing from the many things i ...        1.0\n",
              " 4582  But when i went home, she told me to stop talk...        1.0\n",
              " 4583                              Nemta shook his head.        0.0\n",
              " \n",
              " [4584 rows x 2 columns],\n",
              "                                           SentimentText  Sentiment\n",
              " 0                                   I'm just a dumbass.        1.0\n",
              " 1     I feel like death is flirting with me, always ...        1.0\n",
              " 2     I am now realizing how much I rely on drugs, n...        1.0\n",
              " 3     Submerging, the sharing of emotions, thoughts ...        0.0\n",
              " 4     I feel like even at my most depressed I never ...        1.0\n",
              " ...                                                 ...        ...\n",
              " 1142  Your conscience can try to stop them but its o...        0.0\n",
              " 1143                               The door was locked.        0.0\n",
              " 1144                     it’s just so easy to not care.        0.0\n",
              " 1145  He'd been a fool to think he could survive on ...        0.0\n",
              " 1146  The last world war between NATO and the combin...        0.0\n",
              " \n",
              " [1147 rows x 2 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train.reset_index(drop=True), test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhw7JuROx4k0",
        "outputId": "b4ba0508-5139-4818-ed9e-fcb451d46ad2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4584, 2), (1147, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4HH5FC3x4k4"
      },
      "outputs": [],
      "source": [
        "train.to_csv('/content/drive/My Drive/depressionrnn/train_tweets.csv', index=False)\n",
        "test.to_csv('/content/drive/My Drive/depressionrnn/test_tweets.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wr075uWx4k-"
      },
      "source": [
        "#### defining a funtion to clean the tweets by removing non alphanumeric character and links "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be72LhxIx4k_"
      },
      "outputs": [],
      "source": [
        "def tweet_clean(text):\n",
        "    \n",
        "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text) \n",
        "    text = re.sub(r'https?:/\\/\\S+', ' ', text) \n",
        "    \n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDFTBXkux4lF"
      },
      "source": [
        "####  The tweet column (‘SentimentText’) needs processing and tokenization, so that it can be converted into indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2bc5C4Ux4lF"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n",
        "\n",
        "def tokenizer(s): \n",
        "    return [w.text.lower() for w in nlp(tweet_clean(s))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "6zgZS_Hhx4lI",
        "outputId": "9058a294-b054-4047-dc31-b6c955e3da82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 941 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U torchtext==0.10.0\n",
        "from torchtext.legacy.data import Field, LabelField, TabularDataset, BucketIterator, Iterator\n",
        "TEXT = Field(tokenize = tokenizer)\n",
        "\n",
        "LABEL = LabelField(dtype = torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypKAesKgx4lL"
      },
      "outputs": [],
      "source": [
        "datafields = [('SentimentText', TEXT),('Sentiment', LABEL)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA7pIHUJx4lO"
      },
      "source": [
        "#### We create torchtext dataset,TabularDataset which is specially designed to read csv and tsv files and process them. It is a wrapper around pytorch Dataset with additional features. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHLL6FZqx4lP"
      },
      "outputs": [],
      "source": [
        "trn, tst = TabularDataset.splits(path = '/content/drive/My Drive/depressionrnn', \n",
        "                                                train = 'train_tweets.csv',\n",
        "                                                test = 'test_tweets.csv',    \n",
        "                                                format = 'csv',\n",
        "                                                skip_header = True,\n",
        "                                                fields = datafields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5JKc5Oex4lR",
        "outputId": "dee00be8-23d3-4935-ea9e-d883477e577e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 4584\n",
            "Number of testing examples: 1147\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of training examples: {len(trn)}')\n",
        "print(f'Number of testing examples: {len(tst)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6p-X9lox4lU",
        "outputId": "2a100ee0-3c4f-4708-87fd-db64449eaf37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sentiment': '0.0',\n",
              " 'SentimentText': ['i',\n",
              "  'keep',\n",
              "  'trying',\n",
              "  'and',\n",
              "  'scrambling',\n",
              "  'to',\n",
              "  'pull',\n",
              "  'myself',\n",
              "  'out',\n",
              "  'of',\n",
              "  'this',\n",
              "  'pit',\n",
              "  'but',\n",
              "  'as',\n",
              "  'soon',\n",
              "  'as',\n",
              "  'i',\n",
              "  'm',\n",
              "  'almost',\n",
              "  'out',\n",
              "  'i',\n",
              "  'get',\n",
              "  'slammed',\n",
              "  'into',\n",
              "  'it',\n",
              "  'again']}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "vars(trn.examples[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeR0dYB6x4lX",
        "outputId": "564131d8-876d-470f-ba29-1c7e4b525676"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sentiment': '1.0', 'SentimentText': ['i', 'm', 'just', 'a', 'dumbass']}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "vars(tst.examples[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mm1hzZnx4lb"
      },
      "source": [
        "#### Load pretrained word vectors and build vocabulary\n",
        "Now, instead of having our word embeddings initialized randomly, they are initialized with these pre-trained vectors. We get these vectors simply by specifying which vectors we want and passing it as an argument to build_vocab. TorchText handles downloading the vectors and associating them with the correct words in our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIwIxsI-x4lb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b5010b-2e43-4681-d0b4-f59553008a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.37MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:17<00:00, 23105.50it/s]\n"
          ]
        }
      ],
      "source": [
        "TEXT.build_vocab(trn, max_size=25000,\n",
        "                 vectors=\"glove.6B.100d\",\n",
        "                 unk_init=torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(trn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7Vh_L2Kx4le",
        "outputId": "6bd3088f-d510-470b-89b6-d8c81282b7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('i', 4137), ('the', 2439), ('to', 2270), ('and', 2018), ('a', 1459), ('of', 1169), ('my', 1163), ('it', 1091), ('that', 904), ('in', 847), ('t', 807), ('me', 730), ('was', 698), ('but', 638), ('for', 586), ('m', 579), ('is', 567), ('this', 542), ('you', 528), ('s', 520), ('with', 512), ('have', 493), ('just', 488), ('so', 468), ('on', 430), ('like', 428), ('not', 423), ('he', 417), ('be', 405), ('she', 388), ('at', 374), ('her', 358), ('they', 356), ('do', 351), ('as', 333), ('all', 316), ('feel', 310), ('can', 309), ('don', 309), ('if', 297), ('had', 294), ('what', 283), ('about', 269), ('we', 262), ('know', 251), ('or', 249), ('up', 246), ('one', 246), ('out', 241), ('get', 240)]\n"
          ]
        }
      ],
      "source": [
        "print(TEXT.vocab.freqs.most_common(50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auLV18Hbx4lh",
        "outputId": "59d644f9-62c7-4f88-9f16-0fded662c5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'i', 'the', 'to', 'and', 'a', 'of', 'my', 'it']\n"
          ]
        }
      ],
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDW7iqfVx4lk",
        "outputId": "68178992-4b71-4891-b2d9-a35d5bb5ca3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'0.0': 0, '1.0': 1})\n"
          ]
        }
      ],
      "source": [
        "print(LABEL.vocab.stoi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hSgCTttx4ln"
      },
      "source": [
        "#### Loading the data in batches\n",
        "For data with variable length sentences torchtext provides BucketIterator() dataloader which is wrapper around pytorch Dataloader. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3iQxT-lx4lo"
      },
      "outputs": [],
      "source": [
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "                                (trn, tst),\n",
        "                                batch_size = 64,\n",
        "                                sort_key=lambda x: len(x.SentimentText),\n",
        "                                sort_within_batch=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dahjcq_gx4lq"
      },
      "source": [
        "#### We'll be using a different RNN architecture called a Long Short-Term Memory (LSTM).\n",
        "\n",
        "<b>torch.nn.embedding</b> -A simple lookup table that stores embeddings of a fixed dictionary and size.This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "\n",
        "\n",
        "<b>LSTM</b> - Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.\n",
        "\n",
        "<b>bidirectional</b> - an RNN processing the words in the sentence from the first to the last (a forward RNN), we have a second RNN processing the words in the sentence from the last to the first (a backward RNN). At time step $t$, the forward RNN is processing word $x_t$, and the backward RNN is processing word $x_{T-t+1}$.\n",
        "\n",
        "\n",
        "<b>Dropout</b> - it works by randomly dropping out (setting to 0) neurons in a layer during a forward pass. The probability that each neuron is dropped out is set by a hyperparameter and each neuron with dropout applied is considered indepenently.This helps in regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwvBK0Z3x4lr"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n",
        "                 output_dim, n_layers, bidirectional, dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, \n",
        "                           bidirectional = bidirectional, dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "       \n",
        "        return self.fc(hidden.squeeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVvtaE2hx4lu"
      },
      "source": [
        "To ensure the pre-trained vectors can be loaded into the model, the EMBEDDING_DIM must be equal to that of the pre-trained GloVe vectors loaded earlier.\n",
        "\n",
        "We get our pad token index from the vocabulary, getting the actual string representing the pad token from the field's pad_token attribute, which is pad by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgN2x9qHx4lu"
      },
      "outputs": [],
      "source": [
        "input_dim = len(TEXT.vocab)\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "hidden_dim = 20\n",
        "output_dim = 1\n",
        "\n",
        "n_layers = 2\n",
        "bidirectional = True\n",
        "\n",
        "dropout = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYo5rlbTaJIb",
        "outputId": "8e531caf-3810-4051-9774-96abe8e5d044"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8038"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "input_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a1W_19xx4ly"
      },
      "outputs": [],
      "source": [
        "model = RNN(input_dim, \n",
        "            embedding_dim, \n",
        "            hidden_dim, \n",
        "            output_dim, \n",
        "            n_layers, \n",
        "            bidirectional, \n",
        "            dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSM3SFzKx4l1",
        "outputId": "f0607fb6-d36a-454a-d90f-1c9366dd61a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(8038, 100)\n",
              "  (rnn): GRU(100, 20, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=40, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkVuF1-Ex4l4"
      },
      "source": [
        "We retrieve the embeddings from the field's vocab, and check they're the correct size, [vocab size, embedding dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdiJ1iWSx4l4",
        "outputId": "5756a2fc-5da3-4710-d174-dc5cbc7c9ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8038, 100])\n"
          ]
        }
      ],
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0m6qBQ-x4l7"
      },
      "source": [
        "We then replace the initial weights of the embedding layer with the pre-trained embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9QJVwAOx4l8",
        "outputId": "ec337bab-d824-4f35-8702-8b38973e0910"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0194,  0.4039,  0.2748,  ..., -0.6102, -1.8039,  0.2555],\n",
              "        [-0.4832, -1.0223, -1.1525,  ...,  0.4771,  0.5050, -0.4080],\n",
              "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
              "        ...,\n",
              "        [-0.5879,  0.0165, -0.6412,  ...,  0.1248,  0.0362, -0.3741],\n",
              "        [ 0.5732, -1.0756, -0.1600,  ...,  0.4548,  0.2344,  0.0364],\n",
              "        [-0.2909, -0.7498, -0.2997,  ..., -0.4769,  0.4399, -0.2560]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDxVFgKgx4mA"
      },
      "source": [
        "As our < unk > and < pad > token aren't in the pre-trained vocabulary they have been initialized using unk_init (an $\\mathcal{N}(0,1)$ distribution) when building our vocab. It is preferable to initialize them both to all zeros to explicitly tell our model that, initially, they are irrelevant for determining sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLrRP64wx4mA",
        "outputId": "aab684b0-f91e-4a0c-814a-e3bedc07905d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
            "        ...,\n",
            "        [-0.5879,  0.0165, -0.6412,  ...,  0.1248,  0.0362, -0.3741],\n",
            "        [ 0.5732, -1.0756, -0.1600,  ...,  0.4548,  0.2344,  0.0364],\n",
            "        [-0.2909, -0.7498, -0.2997,  ..., -0.4769,  0.4399, -0.2560]])\n"
          ]
        }
      ],
      "source": [
        "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-hoeQfCx4mD"
      },
      "source": [
        "#### Train the Model\n",
        "\n",
        "We use Adam optimizer and loss function is BCEWithLogitLoss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PkBLvDzx4mE"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.0005)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ9CWMN0x4mJ"
      },
      "source": [
        "#### We define a function for training our model\n",
        "as we are now using dropout, we must remember to use model.train() to ensure the dropout is \"turned on\" while training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2SzsrOOx4mJ"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.SentimentText).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.Sentiment)\n",
        "        \n",
        "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "        correct = (rounded_preds == batch.Sentiment).float() \n",
        "        \n",
        "        acc = correct.sum() / len(correct)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVPNCIGUx4mN",
        "outputId": "c3d7d347-5357-450f-bd56-f5044f833457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch: 01 | Train Loss: 0.182 | Train Acc: 92.70% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 02 | Train Loss: 0.182 | Train Acc: 92.63% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 03 | Train Loss: 0.183 | Train Acc: 92.74% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 04 | Train Loss: 0.194 | Train Acc: 91.84% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 05 | Train Loss: 0.190 | Train Acc: 92.47% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 06 | Train Loss: 0.175 | Train Acc: 93.18% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 07 | Train Loss: 0.195 | Train Acc: 92.38% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 08 | Train Loss: 0.184 | Train Acc: 92.69% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 09 | Train Loss: 0.192 | Train Acc: 92.44% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 10 | Train Loss: 0.186 | Train Acc: 92.27% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 11 | Train Loss: 0.185 | Train Acc: 92.60% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 12 | Train Loss: 0.185 | Train Acc: 92.63% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 13 | Train Loss: 0.196 | Train Acc: 92.18% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 14 | Train Loss: 0.190 | Train Acc: 92.64% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 15 | Train Loss: 0.181 | Train Acc: 92.83% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 16 | Train Loss: 0.187 | Train Acc: 92.72% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 17 | Train Loss: 0.186 | Train Acc: 92.53% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 18 | Train Loss: 0.186 | Train Acc: 92.38% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 19 | Train Loss: 0.187 | Train Acc: 92.80% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 20 | Train Loss: 0.189 | Train Acc: 92.32% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 21 | Train Loss: 0.190 | Train Acc: 92.31% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 22 | Train Loss: 0.179 | Train Acc: 92.99% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 23 | Train Loss: 0.188 | Train Acc: 92.24% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 24 | Train Loss: 0.187 | Train Acc: 92.75% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 25 | Train Loss: 0.182 | Train Acc: 93.08% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 26 | Train Loss: 0.189 | Train Acc: 92.52% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 27 | Train Loss: 0.181 | Train Acc: 93.05% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 28 | Train Loss: 0.190 | Train Acc: 92.41% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 29 | Train Loss: 0.184 | Train Acc: 92.30% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n",
            "| Epoch: 30 | Train Loss: 0.182 | Train Acc: 92.70% |\n",
            "Test Loss: 0.670 | Test Acc: 75.34%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "     \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in test_iterator:\n",
        "\n",
        "            predictions = model(batch.SentimentText).squeeze(1)\n",
        "\n",
        "            loss = criterion(predictions, batch.Sentiment)\n",
        "\n",
        "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "            correct = (rounded_preds == batch.Sentiment).float() \n",
        "            \n",
        "            acc = correct.sum()/len(correct)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "\n",
        "    test_loss = epoch_loss / len(test_iterator)\n",
        "    test_acc = epoch_acc / len(test_iterator)\n",
        "\n",
        "    \n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')\n",
        "    print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6MfHUjEx4mR"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfuzS1z6x4mS",
        "outputId": "e1f488d0-ed13-4d0f-d233-67c0ed2133f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.670 | Test Acc: 75.34%\n"
          ]
        }
      ],
      "source": [
        "epoch_loss = 0\n",
        "epoch_acc = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch in test_iterator:\n",
        "\n",
        "        predictions = model(batch.SentimentText).squeeze(1)\n",
        "\n",
        "        loss = criterion(predictions, batch.Sentiment)\n",
        "\n",
        "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "        correct = (rounded_preds == batch.Sentiment).float() \n",
        "        \n",
        "        acc = correct.sum()/len(correct)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "\n",
        "test_loss = epoch_loss / len(test_iterator)\n",
        "test_acc = epoch_acc / len(test_iterator)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RX_savqx4mV"
      },
      "source": [
        "#### User Input\n",
        "We can now use our model to predict the sentiment of any sentence we give it.As it has been trained on tweets, the sentences provided should in a positive or a negative context.\n",
        "\n",
        "We are expecting tweets with a negative sentiment to return a value close to 1 and positive tweets to return a value close to 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8juRfr9x4mV"
      },
      "outputs": [],
      "source": [
        "sentence = ' '#input(\"Enter you sentiment: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jvsMXlgx4mY"
      },
      "outputs": [],
      "source": [
        "tokenized = [tok.text for tok in nlp.tokenizer(sentence)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okpg-GWEx4mb"
      },
      "outputs": [],
      "source": [
        "indexed = [TEXT.vocab.stoi[t] for t in tokenized]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y22hVPzdx4mf"
      },
      "outputs": [],
      "source": [
        "tensor = torch.LongTensor(indexed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ijxjMkjx4mi"
      },
      "outputs": [],
      "source": [
        "tensor = tensor.unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37TEQqXxx4ml"
      },
      "outputs": [],
      "source": [
        "prediction = torch.sigmoid(model(tensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFHYlXEYx4mo",
        "outputId": "75c82953-3999-46a3-ddb5-d2de1a8e9ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3342277705669403\n",
            "Patient showing mild signs of depression.\n"
          ]
        }
      ],
      "source": [
        "pred = prediction.item()\n",
        "print(pred)\n",
        "if pred<0.3:\n",
        "  print(\"Patient showing no signs of depression.\")\n",
        "elif pred>0.7:\n",
        "  print(\"Patient showing severe signs of deperession.\")\n",
        "else:\n",
        "  print(\"Patient showing mild signs of depression.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryZVfYkYx4ms"
      },
      "outputs": [],
      "source": [
        "torch.save(model, '/content/drive/My Drive/depressionrnn/seventysix.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLgGIaxVx4mv",
        "outputId": "86c7965c-3721-43d6-e31b-d9cd7a73bbef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  unpickler.persistent_load = persistent_load\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.GRU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  unpickler.persistent_load = persistent_load\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  unpickler.persistent_load = persistent_load\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  unpickler.persistent_load = persistent_load\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(8038, 100)\n",
              "  (rnn): GRU(100, 20, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=40, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "model = torch.load('/content/drive/My Drive/depressionrnn/eightyALL.pt')\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNJctbX0oNv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ceff3a8-84eb-4ea2-f737-b1647d918fe6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00],\n",
              "         [-2.5223e-04,  3.6638e-02, -1.2487e-02,  ...,  7.1077e-02,\n",
              "          -6.3295e-03, -4.3267e-02],\n",
              "         [-1.5668e-02,  5.9423e-01,  6.9866e-01,  ..., -4.8228e-01,\n",
              "           4.0013e-02,  8.0493e-01],\n",
              "         ...,\n",
              "         [-7.0798e-01, -1.0008e-01, -7.5247e-01,  ...,  2.3203e-01,\n",
              "          -9.9558e-02, -2.4126e-01],\n",
              "         [ 5.0150e-01, -1.1540e+00, -2.2011e-01,  ...,  5.4036e-01,\n",
              "           2.1950e-01,  1.2718e-01],\n",
              "         [-3.6145e-01, -8.6555e-01, -3.8274e-01,  ..., -5.0392e-01,\n",
              "           4.9332e-01, -1.9343e-01]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0389,  0.1417,  0.1798,  ..., -0.1074,  0.1154, -0.1111],\n",
              "         [ 0.0304, -0.0568, -0.1228,  ...,  0.1031,  0.2214, -0.0489],\n",
              "         [-0.1973,  0.0014,  0.1398,  ...,  0.1347,  0.0105, -0.0006],\n",
              "         ...,\n",
              "         [-0.1481, -0.0159,  0.2606,  ...,  0.1536, -0.1178, -0.0721],\n",
              "         [ 0.0489, -0.1487,  0.1835,  ..., -0.1672, -0.1767, -0.0013],\n",
              "         [ 0.2594,  0.0608,  0.1482,  ...,  0.1884, -0.1939,  0.0280]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0370,  0.0092, -0.2192,  ..., -0.1160,  0.1792, -0.0550],\n",
              "         [-0.2595, -0.2041, -0.3113,  ...,  0.0485,  0.1925, -0.1656],\n",
              "         [-0.3452, -0.1886,  0.0037,  ..., -0.0512,  0.2115, -0.0836],\n",
              "         ...,\n",
              "         [ 0.0822, -0.1759,  0.0744,  ..., -0.0906, -0.0812,  0.0410],\n",
              "         [-0.1433, -0.2440, -0.0131,  ..., -0.1730,  0.0230,  0.0536],\n",
              "         [ 0.0247,  0.1282, -0.1340,  ..., -0.2507,  0.1730, -0.1437]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.1092, -0.0853,  0.0167, -0.0683,  0.0955,  0.1128, -0.0419, -0.1580,\n",
              "         -0.2288, -0.0386,  0.3133,  0.2113, -0.0712,  0.1161, -0.0191,  0.0711,\n",
              "          0.0960, -0.1584,  0.2660, -0.0288,  0.0945, -0.0538,  0.2328,  0.2147,\n",
              "          0.1992,  0.2023,  0.3354,  0.1276, -0.0377,  0.2505, -0.1461,  0.0372,\n",
              "          0.1582,  0.1056,  0.2770, -0.1247, -0.1226,  0.1377,  0.2475,  0.0284,\n",
              "         -0.0014,  0.0870,  0.1704, -0.2032,  0.1989,  0.1120, -0.1040,  0.0497,\n",
              "         -0.2411, -0.1957, -0.0296, -0.1737,  0.1113, -0.1635, -0.0304,  0.0372,\n",
              "          0.1359,  0.0224,  0.0045,  0.0899], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1765,  0.1031,  0.2814, -0.1422,  0.0082,  0.0303,  0.1491,  0.0889,\n",
              "         -0.1493, -0.0699,  0.0638, -0.0392,  0.1407,  0.0068, -0.1769,  0.1349,\n",
              "         -0.0939, -0.2079, -0.0767, -0.1815,  0.2369,  0.1442, -0.0708,  0.0932,\n",
              "          0.1479, -0.0568,  0.1630,  0.0901,  0.0406,  0.1373, -0.0037, -0.0681,\n",
              "          0.0329, -0.0575,  0.1975,  0.0679,  0.2642,  0.1199, -0.0404, -0.0931,\n",
              "          0.1789, -0.0779,  0.0531, -0.0099, -0.1093, -0.1055, -0.0392,  0.0727,\n",
              "         -0.1160,  0.0418,  0.1909, -0.0334, -0.1492,  0.0561, -0.1050,  0.0459,\n",
              "          0.1622, -0.1406, -0.1681,  0.1602], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0345, -0.1273,  0.0242,  ..., -0.2223,  0.1683,  0.3636],\n",
              "         [-0.0741,  0.0612,  0.1508,  ..., -0.2246,  0.2265, -0.0924],\n",
              "         [-0.2788, -0.2100,  0.1099,  ...,  0.2655, -0.0052,  0.2326],\n",
              "         ...,\n",
              "         [-0.1915, -0.2346, -0.0506,  ...,  0.0018,  0.0866,  0.2077],\n",
              "         [ 0.0544, -0.1274,  0.1708,  ..., -0.2088, -0.0447, -0.0243],\n",
              "         [ 0.1683,  0.0554,  0.1518,  ...,  0.2039, -0.1493, -0.2608]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0848, -0.1065, -0.0358,  ...,  0.1418,  0.1808,  0.1280],\n",
              "         [ 0.0738,  0.0008, -0.1148,  ..., -0.1629,  0.0546,  0.0681],\n",
              "         [ 0.0616, -0.2231, -0.0281,  ...,  0.0718,  0.1336,  0.0054],\n",
              "         ...,\n",
              "         [-0.2435,  0.2941, -0.1565,  ...,  0.1983,  0.0626,  0.0624],\n",
              "         [-0.0465,  0.1405, -0.1880,  ...,  0.1591,  0.2728, -0.2961],\n",
              "         [ 0.0725,  0.1467,  0.0978,  ..., -0.1992, -0.0257,  0.1341]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0755,  0.1317, -0.0658, -0.2054, -0.1199, -0.1839,  0.1251, -0.2368,\n",
              "         -0.0952, -0.0893, -0.2556,  0.2327, -0.0365,  0.1240,  0.0857,  0.2116,\n",
              "         -0.0649,  0.0959,  0.1782, -0.1883, -0.0302, -0.0603, -0.0343, -0.0431,\n",
              "         -0.0713,  0.1266, -0.1893, -0.0576, -0.0213, -0.1548,  0.1252,  0.1328,\n",
              "          0.0599,  0.1824,  0.1219, -0.1983,  0.1537, -0.1678,  0.3554, -0.0517,\n",
              "          0.0222, -0.1314,  0.1465, -0.1479,  0.1992,  0.0088, -0.1035,  0.0778,\n",
              "          0.2187, -0.0158, -0.1297, -0.1304, -0.1746,  0.0886, -0.1536, -0.0710,\n",
              "          0.0499, -0.0305,  0.0699, -0.2039], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0451, -0.0524,  0.0964, -0.2474, -0.0969,  0.2199,  0.0720,  0.0497,\n",
              "         -0.1367, -0.0845, -0.1155, -0.1227,  0.0766, -0.0061, -0.2833,  0.3210,\n",
              "          0.0959, -0.0334,  0.0811,  0.0059, -0.0318, -0.1398, -0.1800, -0.0187,\n",
              "          0.1482, -0.1973, -0.0679, -0.1925, -0.0794,  0.0598, -0.1475, -0.0596,\n",
              "          0.1224,  0.0264, -0.1338, -0.0090, -0.1234, -0.2008, -0.0587,  0.1047,\n",
              "          0.1912,  0.1235,  0.2133, -0.1900,  0.1256, -0.2184, -0.1998,  0.0493,\n",
              "          0.0570,  0.1107,  0.1473,  0.1202, -0.0867, -0.0499, -0.1643,  0.2697,\n",
              "         -0.0965, -0.1922,  0.2157,  0.0642], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0824,  0.1616,  0.2379,  ...,  0.0805,  0.0915, -0.1189],\n",
              "         [ 0.2467, -0.0936, -0.2160,  ...,  0.1682,  0.0243,  0.2638],\n",
              "         [ 0.1720,  0.0525,  0.0512,  ..., -0.2222, -0.0324, -0.1584],\n",
              "         ...,\n",
              "         [ 0.0038,  0.1781, -0.1416,  ...,  0.0508,  0.1588, -0.0404],\n",
              "         [-0.2161, -0.1492,  0.0478,  ...,  0.0006,  0.0285, -0.0494],\n",
              "         [ 0.1949, -0.1671, -0.1352,  ..., -0.1100,  0.0866, -0.0947]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.1706, -0.1395, -0.1053,  ...,  0.1013, -0.0396, -0.0412],\n",
              "         [-0.2573,  0.0425,  0.0949,  ...,  0.1889,  0.1667, -0.2288],\n",
              "         [ 0.1442,  0.0004,  0.1649,  ..., -0.1528,  0.0336,  0.0711],\n",
              "         ...,\n",
              "         [ 0.0212,  0.2434, -0.1804,  ..., -0.1488, -0.0873, -0.0278],\n",
              "         [ 0.0373,  0.2201,  0.1262,  ...,  0.1244,  0.1594, -0.0867],\n",
              "         [-0.1714, -0.0110, -0.2178,  ...,  0.0523, -0.0909,  0.0855]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0819, -0.0735, -0.0107, -0.0235, -0.1441, -0.1639, -0.1097, -0.0427,\n",
              "         -0.0239, -0.0439, -0.0384, -0.2005,  0.2122,  0.1272,  0.1566, -0.0939,\n",
              "         -0.2597, -0.0730, -0.2006,  0.0098, -0.0466, -0.0807,  0.2943, -0.0060,\n",
              "          0.0199,  0.1094,  0.1633,  0.1654,  0.0025, -0.0510, -0.0973,  0.0471,\n",
              "         -0.0240,  0.0212,  0.1240,  0.0855, -0.0923,  0.1386, -0.2245, -0.0888,\n",
              "          0.2323, -0.0155, -0.1059, -0.1387,  0.0358,  0.0373,  0.0811,  0.2308,\n",
              "         -0.0797,  0.0856,  0.1283, -0.0284,  0.2159, -0.2122, -0.0831, -0.1933,\n",
              "         -0.1517, -0.1263, -0.1674,  0.1851], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0764, -0.0976,  0.0251, -0.1554, -0.1438,  0.1572, -0.0197, -0.1596,\n",
              "         -0.1797,  0.0848, -0.1933, -0.0829,  0.0660, -0.1371,  0.1265, -0.0149,\n",
              "          0.0439, -0.1575, -0.0355, -0.1456,  0.0387,  0.0203,  0.0045, -0.2018,\n",
              "          0.2222,  0.1369,  0.0987,  0.0774, -0.1689, -0.1574,  0.0949,  0.2254,\n",
              "         -0.0805,  0.1226, -0.0163, -0.0555, -0.0965, -0.0532,  0.0012, -0.1882,\n",
              "         -0.1703, -0.0976,  0.0318, -0.0217,  0.1192, -0.2184, -0.0778, -0.0209,\n",
              "          0.0406,  0.0835,  0.0320, -0.0653,  0.2201, -0.1435, -0.0533,  0.0532,\n",
              "          0.0294, -0.0145, -0.1742, -0.1683], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.2240, -0.0213,  0.3014,  ..., -0.0480,  0.1117,  0.1653],\n",
              "         [ 0.0631,  0.2167, -0.0242,  ..., -0.1658,  0.0586, -0.1832],\n",
              "         [ 0.1625, -0.2596,  0.0647,  ..., -0.1069, -0.0580, -0.0342],\n",
              "         ...,\n",
              "         [-0.1451,  0.0899, -0.2068,  ..., -0.0400, -0.0400, -0.0665],\n",
              "         [ 0.0231,  0.0258, -0.2611,  ..., -0.1361,  0.0995,  0.0730],\n",
              "         [-0.1254,  0.1295,  0.0997,  ...,  0.1250,  0.1869, -0.0466]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.2382,  0.2001, -0.1299,  ...,  0.1070,  0.0974, -0.1032],\n",
              "         [-0.2444,  0.0534,  0.0883,  ..., -0.1597, -0.0699,  0.0408],\n",
              "         [-0.2951, -0.0148,  0.0745,  ...,  0.1347,  0.0533,  0.2025],\n",
              "         ...,\n",
              "         [ 0.3568,  0.0441,  0.1534,  ..., -0.1318,  0.1226,  0.0073],\n",
              "         [ 0.3055,  0.0309,  0.0858,  ..., -0.0537, -0.1627, -0.0829],\n",
              "         [-0.0437,  0.0275,  0.0008,  ...,  0.0234,  0.1512, -0.0465]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0300,  0.1190, -0.0244,  0.1574,  0.0788,  0.1869,  0.2107, -0.0745,\n",
              "          0.0488,  0.3065, -0.1614,  0.2159,  0.1114,  0.1757,  0.0683,  0.0458,\n",
              "         -0.1176, -0.0131,  0.3202,  0.1262,  0.3253,  0.0319,  0.1522, -0.2531,\n",
              "         -0.0043,  0.0951,  0.2826,  0.0861, -0.1120,  0.0326, -0.2646,  0.2595,\n",
              "          0.2253, -0.0103, -0.1204,  0.1159,  0.1395,  0.1903, -0.0624,  0.0296,\n",
              "         -0.1989, -0.0679, -0.2154,  0.1410, -0.0283, -0.1359, -0.0375, -0.2060,\n",
              "         -0.0509, -0.2080, -0.0518, -0.0526, -0.1044,  0.1664,  0.0439, -0.1204,\n",
              "         -0.1291,  0.1299, -0.0612,  0.2313], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0421, -0.0562,  0.1696,  0.0542, -0.0653,  0.1156,  0.2030, -0.1242,\n",
              "         -0.0888,  0.2254,  0.1522,  0.2264, -0.1402, -0.0349,  0.2185,  0.2772,\n",
              "          0.1082,  0.1431,  0.0789, -0.1210,  0.0686, -0.1889, -0.0615, -0.1741,\n",
              "         -0.1044,  0.1806,  0.1219, -0.1497, -0.0990,  0.2991, -0.0472,  0.0677,\n",
              "         -0.1096,  0.2154,  0.0493,  0.1822,  0.1141,  0.0967, -0.0098,  0.1082,\n",
              "         -0.2239,  0.1407,  0.0424,  0.1157, -0.1228, -0.1399, -0.0110,  0.1777,\n",
              "          0.1704, -0.1438,  0.1065, -0.1201,  0.1077, -0.1760, -0.0939, -0.0488,\n",
              "          0.2586, -0.0624,  0.0948,  0.2131], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.1133, -0.0862, -0.1000,  0.0349, -0.0461,  0.1092, -0.0783, -0.0322,\n",
              "           0.1008,  0.0622, -0.0480,  0.0409, -0.1083,  0.1198,  0.0738,  0.0501,\n",
              "           0.1381,  0.0560,  0.0928, -0.0513,  0.3745, -0.2902,  0.2743,  0.1810,\n",
              "          -0.3280,  0.2839,  0.2822,  0.3185, -0.3272,  0.2721, -0.2547, -0.3385,\n",
              "          -0.1911, -0.2523,  0.2676, -0.2414, -0.3289,  0.3301,  0.2295, -0.3569]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0730], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "list(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fOLNZ3O03iq"
      },
      "source": [
        "Now We gotta build the second RNN to understand the relations between sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of2NWhpGoUbF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fovP7kTc54RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ffeb1a-7c32-43e5-fb19-6e038d347dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "import nltk \n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zovsnOFx7RWZ"
      },
      "outputs": [],
      "source": [
        "para = pd.read_csv('/content/drive/My Drive/depressionrnn/paradataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlEC8MNx8eFU"
      },
      "outputs": [],
      "source": [
        "lmao=para[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv9taXVl9fy2"
      },
      "outputs": [],
      "source": [
        "input_data = {'condition':[]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV9MrFNJ7hln"
      },
      "outputs": [],
      "source": [
        "for i in range(len(para)):\n",
        "  input_data['condition'].append(para.loc[i, \"condition\"])\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYf6ie_qe9if"
      },
      "outputs": [],
      "source": [
        "to_mer= pd.DataFrame(input_data,columns =['condition'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDjViLZ-vpeS"
      },
      "outputs": [],
      "source": [
        "l=0\n",
        "m=0\n",
        "for i in range(len(para)):\n",
        "  sent_tokens = sent_tokenize(para.loc[i, \"submission\"])\n",
        "  l=l+len(sent_tokens)\n",
        "m=l/i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IApgYdr2v8RB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "201695ff-eb04-41c7-8faa-173d78e95f6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35.506864988558355"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cm_Mrryxhkn"
      },
      "outputs": [],
      "source": [
        "vec_sentence = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NPtFU5Ax7JH"
      },
      "outputs": [],
      "source": [
        "for i in range(len(para)):\n",
        "  sent_tokens = sent_tokenize(para.loc[i, \"submission\"])\n",
        "  for i in range(len(sent_tokens)):\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sent_tokens[i])]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    vec_sentence.setdefault(i,[]).append(prediction.item())\n",
        "  if i<580:\n",
        "    for i in range(i+1,580):\n",
        "      vec_sentence.setdefault(i,[]).append(0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr_S5aPA2gLc"
      },
      "outputs": [],
      "source": [
        "vec_sent = pd.DataFrame(vec_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSxRVg-d9saQ"
      },
      "outputs": [],
      "source": [
        "average_vec_sent=vec_sent.iloc[:,0:36]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEiiye0vA67K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "2cf01f0b-bbee-42d1-a0a7-3982f990124f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6   \\\n",
              "50   0.150976  0.008347  0.005640  0.865229  0.962581  0.886694  0.006633   \n",
              "623  0.004346  0.003721  0.003842  0.041290  0.914255  0.897180  0.966135   \n",
              "\n",
              "           7         8         9   ...   26   27   28   29   30   31   32  \\\n",
              "50   0.006327  0.869093  0.006765  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "623  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "      33   34   35  \n",
              "50   0.0  0.0  0.0  \n",
              "623  0.0  0.0  0.0  \n",
              "\n",
              "[2 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c832dccc-f4ba-44b4-9dae-7f77e8305b1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.150976</td>\n",
              "      <td>0.008347</td>\n",
              "      <td>0.005640</td>\n",
              "      <td>0.865229</td>\n",
              "      <td>0.962581</td>\n",
              "      <td>0.886694</td>\n",
              "      <td>0.006633</td>\n",
              "      <td>0.006327</td>\n",
              "      <td>0.869093</td>\n",
              "      <td>0.006765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>0.004346</td>\n",
              "      <td>0.003721</td>\n",
              "      <td>0.003842</td>\n",
              "      <td>0.041290</td>\n",
              "      <td>0.914255</td>\n",
              "      <td>0.897180</td>\n",
              "      <td>0.966135</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c832dccc-f4ba-44b4-9dae-7f77e8305b1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c832dccc-f4ba-44b4-9dae-7f77e8305b1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c832dccc-f4ba-44b4-9dae-7f77e8305b1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "average_vec_sent.sample(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFzjZiIAxawS"
      },
      "source": [
        "mean value of number of sentences = 36"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sCA7beq_0Ye"
      },
      "outputs": [],
      "source": [
        "data_para_vectors = pd.DataFrame.from_dict(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woa7LHd-1RHL"
      },
      "outputs": [],
      "source": [
        "sent_tokens = sent_tokenize(\"\") \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Otzfui2-1cWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff27d55f-ddff-4cdc-b7a3-fe948e890de4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "input_data = []\n",
        "sent_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG7UZmyF6ASw"
      },
      "outputs": [],
      "source": [
        "for sentence in sent_tokens:\n",
        "  tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "  indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "  tensor = torch.LongTensor(indexed)\n",
        "  tensor = tensor.unsqueeze(1)\n",
        "  prediction = torch.sigmoid(model(tensor))\n",
        "  input_data.append(prediction.item())\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4t0Lj7W6qr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae2aac8-9b30-4427-9c9b-5fd10a6374dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ],
      "source": [
        "input_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0wDQQLZD_Cw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAxAyaUnBrox",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f7b10252-6704-4bca-9ddb-bc117fe6dcd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      condition\n",
              "0             0\n",
              "1             1\n",
              "2             0\n",
              "3             1\n",
              "4             0\n",
              "...         ...\n",
              "1744          0\n",
              "1745          0\n",
              "1746          1\n",
              "1747          0\n",
              "1748          1\n",
              "\n",
              "[1749 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1955314d-cd9c-411f-9883-67374823e4b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1745</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1746</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1747</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1748</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1749 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1955314d-cd9c-411f-9883-67374823e4b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1955314d-cd9c-411f-9883-67374823e4b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1955314d-cd9c-411f-9883-67374823e4b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "data_para_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNhOVpVPAU_-"
      },
      "outputs": [],
      "source": [
        "data_para_vectors.to_csv('/content/drive/My Drive/depressionrnn/para_vectors.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCQhqipPBkiT"
      },
      "outputs": [],
      "source": [
        "data_para_vectors = pd.read_csv('/content/drive/My Drive/depressionrnn/para_vectors.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hsq7EK5KxGq"
      },
      "outputs": [],
      "source": [
        "to_mer = data_para_vectors.iloc[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXAVapCXBgyS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "bd7515c1-c895-4a39-acbd-bfc1ea2b7d4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
              "\n",
              "[1749 rows x 0 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac00e744-e931-4830-b482-fdb1bd0b2697\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1745</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1746</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1747</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1748</th>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1749 rows × 0 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac00e744-e931-4830-b482-fdb1bd0b2697')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac00e744-e931-4830-b482-fdb1bd0b2697 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac00e744-e931-4830-b482-fdb1bd0b2697');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "to_mer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wd15lWiCZ5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d6cf92c1-ecca-48bf-8f59-41ab7f025ad9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6   \\\n",
              "0     0.009523  0.658102  0.003042  0.603045  0.003387  0.003748  0.009408   \n",
              "1     0.039839  0.010238  0.011331  0.000000  0.000000  0.000000  0.000000   \n",
              "2     0.002819  0.751334  0.002634  0.178543  0.184734  0.518720  0.673035   \n",
              "3     0.978511  0.770082  0.982007  0.507165  0.205545  0.939843  0.972285   \n",
              "4     0.003982  0.002564  0.003708  0.002808  0.002821  0.025512  0.003431   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1742  0.004857  0.003203  0.003775  0.004833  0.012411  0.003711  0.005891   \n",
              "1743  0.004149  0.003363  0.003631  0.004823  0.004946  0.003932  0.003472   \n",
              "1744  0.650540  0.950960  0.985101  0.986493  0.605750  0.003750  0.990080   \n",
              "1745  0.012208  0.003697  0.006580  0.000000  0.000000  0.000000  0.000000   \n",
              "1746  0.412105  0.619846  0.987971  0.071265  0.209126  0.190367  0.457180   \n",
              "\n",
              "            7         8         9   ...        26        27        28  \\\n",
              "0     0.003200  0.004350  0.003460  ...  0.006842  0.003221  0.163021   \n",
              "1     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "2     0.004613  0.057634  0.024432  ...  0.000000  0.000000  0.000000   \n",
              "3     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "4     0.005095  0.012824  0.005832  ...  0.000000  0.000000  0.000000   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1742  0.003233  0.003964  0.020038  ...  0.003991  0.002900  0.003699   \n",
              "1743  0.003024  0.003240  0.030856  ...  0.003525  0.003385  0.003629   \n",
              "1744  0.375325  0.004041  0.462347  ...  0.976964  0.774587  0.934288   \n",
              "1745  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "1746  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "\n",
              "            29        30        31        32        33        34        35  \n",
              "0     0.645470  0.057917  0.005478  0.002520  0.237447  0.005587  0.040844  \n",
              "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "1742  0.004137  0.003127  0.003848  0.002310  0.003615  0.004008  0.003017  \n",
              "1743  0.003058  0.103539  0.911722  0.003129  0.003277  0.005431  0.006394  \n",
              "1744  0.012654  0.004412  0.857281  0.307475  0.983027  0.008949  0.053964  \n",
              "1745  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1746  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "\n",
              "[1747 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9e350db-3080-4287-9689-4f9563c2e9d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.009523</td>\n",
              "      <td>0.658102</td>\n",
              "      <td>0.003042</td>\n",
              "      <td>0.603045</td>\n",
              "      <td>0.003387</td>\n",
              "      <td>0.003748</td>\n",
              "      <td>0.009408</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.004350</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006842</td>\n",
              "      <td>0.003221</td>\n",
              "      <td>0.163021</td>\n",
              "      <td>0.645470</td>\n",
              "      <td>0.057917</td>\n",
              "      <td>0.005478</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>0.237447</td>\n",
              "      <td>0.005587</td>\n",
              "      <td>0.040844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.039839</td>\n",
              "      <td>0.010238</td>\n",
              "      <td>0.011331</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002819</td>\n",
              "      <td>0.751334</td>\n",
              "      <td>0.002634</td>\n",
              "      <td>0.178543</td>\n",
              "      <td>0.184734</td>\n",
              "      <td>0.518720</td>\n",
              "      <td>0.673035</td>\n",
              "      <td>0.004613</td>\n",
              "      <td>0.057634</td>\n",
              "      <td>0.024432</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.978511</td>\n",
              "      <td>0.770082</td>\n",
              "      <td>0.982007</td>\n",
              "      <td>0.507165</td>\n",
              "      <td>0.205545</td>\n",
              "      <td>0.939843</td>\n",
              "      <td>0.972285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.003982</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>0.003708</td>\n",
              "      <td>0.002808</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>0.025512</td>\n",
              "      <td>0.003431</td>\n",
              "      <td>0.005095</td>\n",
              "      <td>0.012824</td>\n",
              "      <td>0.005832</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742</th>\n",
              "      <td>0.004857</td>\n",
              "      <td>0.003203</td>\n",
              "      <td>0.003775</td>\n",
              "      <td>0.004833</td>\n",
              "      <td>0.012411</td>\n",
              "      <td>0.003711</td>\n",
              "      <td>0.005891</td>\n",
              "      <td>0.003233</td>\n",
              "      <td>0.003964</td>\n",
              "      <td>0.020038</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003991</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>0.003699</td>\n",
              "      <td>0.004137</td>\n",
              "      <td>0.003127</td>\n",
              "      <td>0.003848</td>\n",
              "      <td>0.002310</td>\n",
              "      <td>0.003615</td>\n",
              "      <td>0.004008</td>\n",
              "      <td>0.003017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1743</th>\n",
              "      <td>0.004149</td>\n",
              "      <td>0.003363</td>\n",
              "      <td>0.003631</td>\n",
              "      <td>0.004823</td>\n",
              "      <td>0.004946</td>\n",
              "      <td>0.003932</td>\n",
              "      <td>0.003472</td>\n",
              "      <td>0.003024</td>\n",
              "      <td>0.003240</td>\n",
              "      <td>0.030856</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>0.003385</td>\n",
              "      <td>0.003629</td>\n",
              "      <td>0.003058</td>\n",
              "      <td>0.103539</td>\n",
              "      <td>0.911722</td>\n",
              "      <td>0.003129</td>\n",
              "      <td>0.003277</td>\n",
              "      <td>0.005431</td>\n",
              "      <td>0.006394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744</th>\n",
              "      <td>0.650540</td>\n",
              "      <td>0.950960</td>\n",
              "      <td>0.985101</td>\n",
              "      <td>0.986493</td>\n",
              "      <td>0.605750</td>\n",
              "      <td>0.003750</td>\n",
              "      <td>0.990080</td>\n",
              "      <td>0.375325</td>\n",
              "      <td>0.004041</td>\n",
              "      <td>0.462347</td>\n",
              "      <td>...</td>\n",
              "      <td>0.976964</td>\n",
              "      <td>0.774587</td>\n",
              "      <td>0.934288</td>\n",
              "      <td>0.012654</td>\n",
              "      <td>0.004412</td>\n",
              "      <td>0.857281</td>\n",
              "      <td>0.307475</td>\n",
              "      <td>0.983027</td>\n",
              "      <td>0.008949</td>\n",
              "      <td>0.053964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1745</th>\n",
              "      <td>0.012208</td>\n",
              "      <td>0.003697</td>\n",
              "      <td>0.006580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1746</th>\n",
              "      <td>0.412105</td>\n",
              "      <td>0.619846</td>\n",
              "      <td>0.987971</td>\n",
              "      <td>0.071265</td>\n",
              "      <td>0.209126</td>\n",
              "      <td>0.190367</td>\n",
              "      <td>0.457180</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1747 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9e350db-3080-4287-9689-4f9563c2e9d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9e350db-3080-4287-9689-4f9563c2e9d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9e350db-3080-4287-9689-4f9563c2e9d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "average_vec_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENojj7ozC2_X"
      },
      "outputs": [],
      "source": [
        "sent_numeric = pd.merge(to_mer,average_vec_sent,left_index=True,right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogJXGaEsDagM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "e42339d3-c62f-4a87-ad6f-f4875726c6dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6   \\\n",
              "345   0.003739  0.002714  0.003639  0.003352  0.002592  0.003716  0.004022   \n",
              "1054  0.004346  0.004062  0.004134  0.003425  0.004015  0.003840  0.003298   \n",
              "296   0.971720  0.060219  0.259715  0.002901  0.979903  0.940727  0.847780   \n",
              "934   0.003042  0.003001  0.003813  0.003149  0.010379  0.002838  0.003128   \n",
              "951   0.002676  0.603920  0.021843  0.000000  0.000000  0.000000  0.000000   \n",
              "1302  0.946045  0.004420  0.016068  0.297421  0.000000  0.000000  0.000000   \n",
              "1284  0.002995  0.002795  0.008353  0.003317  0.003185  0.175251  0.002905   \n",
              "1326  0.005099  0.007573  0.006884  0.003046  0.002712  0.006537  0.008116   \n",
              "380   0.122099  0.004643  0.002830  0.002887  0.003398  0.002690  0.002946   \n",
              "1378  0.053530  0.034053  0.030367  0.004953  0.041402  0.005340  0.003218   \n",
              "748   0.022138  0.003237  0.824580  0.004466  0.013986  0.002854  0.883635   \n",
              "1393  0.004592  0.003370  0.004448  0.002831  0.002786  0.003396  0.002975   \n",
              "1092  0.003462  0.004340  0.003657  0.002716  0.004075  0.002990  0.005523   \n",
              "1644  0.964090  0.004165  0.073153  0.007030  0.005139  0.007811  0.000000   \n",
              "1693  0.006282  0.029984  0.158722  0.000000  0.000000  0.000000  0.000000   \n",
              "1187  0.003809  0.009630  0.003317  0.150510  0.712594  0.006008  0.008794   \n",
              "944   0.002860  0.003094  0.004355  0.004013  0.036935  0.006040  0.005223   \n",
              "1526  0.007434  0.003950  0.977403  0.004760  0.012159  0.004952  0.002633   \n",
              "850   0.967926  0.528449  0.007728  0.017828  0.010350  0.967529  0.960840   \n",
              "242   0.002848  0.006324  0.006319  0.005851  0.235387  0.003245  0.005470   \n",
              "\n",
              "            7         8         9   ...        26        27        28  \\\n",
              "345   0.002920  0.002931  0.002831  ...  0.003358  0.003705  0.003159   \n",
              "1054  0.002650  0.006948  0.003081  ...  0.000000  0.000000  0.000000   \n",
              "296   0.089426  0.097354  0.234356  ...  0.000000  0.000000  0.000000   \n",
              "934   0.004421  0.002669  0.004116  ...  0.002929  0.003413  0.004079   \n",
              "951   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "1302  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "1284  0.257791  0.003889  0.004943  ...  0.003411  0.006067  0.011476   \n",
              "1326  0.035238  0.029697  0.002185  ...  0.000000  0.000000  0.000000   \n",
              "380   0.004517  0.004198  0.002835  ...  0.000000  0.000000  0.000000   \n",
              "1378  0.973586  0.989915  0.976708  ...  0.000000  0.000000  0.000000   \n",
              "748   0.003051  0.002812  0.662720  ...  0.000000  0.000000  0.000000   \n",
              "1393  0.002752  0.010654  0.006144  ...  0.000000  0.000000  0.000000   \n",
              "1092  0.003019  0.037799  0.002814  ...  0.730541  0.024383  0.012547   \n",
              "1644  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "1693  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "1187  0.002470  0.002604  0.015849  ...  0.000000  0.000000  0.000000   \n",
              "944   0.003938  0.003802  0.003517  ...  0.003140  0.004070  0.005370   \n",
              "1526  0.122099  0.073003  0.010125  ...  0.004437  0.005656  0.003343   \n",
              "850   0.944907  0.977816  0.005301  ...  0.000000  0.000000  0.000000   \n",
              "242   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "\n",
              "            29        30        31        32        33        34        35  \n",
              "345   0.003861  0.002738  0.003163  0.003104  0.004067  0.003149  0.002686  \n",
              "1054  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "296   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "934   0.003499  0.003313  0.004202  0.003486  0.004736  0.003979  0.010751  \n",
              "951   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1302  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1284  0.002852  0.006034  0.005113  0.000000  0.000000  0.000000  0.000000  \n",
              "1326  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "380   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1378  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "748   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1393  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1092  0.042445  0.064836  0.002821  0.008199  0.003847  0.003263  0.075462  \n",
              "1644  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1693  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1187  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "944   0.003811  0.002996  0.004794  0.005304  0.009126  0.007353  0.003869  \n",
              "1526  0.002679  0.003187  0.007975  0.005797  0.103736  0.163021  0.163021  \n",
              "850   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "242   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "\n",
              "[20 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18fdb0a2-5cad-4e04-9bd5-9314a097ca47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>0.003739</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>0.003639</td>\n",
              "      <td>0.003352</td>\n",
              "      <td>0.002592</td>\n",
              "      <td>0.003716</td>\n",
              "      <td>0.004022</td>\n",
              "      <td>0.002920</td>\n",
              "      <td>0.002931</td>\n",
              "      <td>0.002831</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003358</td>\n",
              "      <td>0.003705</td>\n",
              "      <td>0.003159</td>\n",
              "      <td>0.003861</td>\n",
              "      <td>0.002738</td>\n",
              "      <td>0.003163</td>\n",
              "      <td>0.003104</td>\n",
              "      <td>0.004067</td>\n",
              "      <td>0.003149</td>\n",
              "      <td>0.002686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>0.004346</td>\n",
              "      <td>0.004062</td>\n",
              "      <td>0.004134</td>\n",
              "      <td>0.003425</td>\n",
              "      <td>0.004015</td>\n",
              "      <td>0.003840</td>\n",
              "      <td>0.003298</td>\n",
              "      <td>0.002650</td>\n",
              "      <td>0.006948</td>\n",
              "      <td>0.003081</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0.971720</td>\n",
              "      <td>0.060219</td>\n",
              "      <td>0.259715</td>\n",
              "      <td>0.002901</td>\n",
              "      <td>0.979903</td>\n",
              "      <td>0.940727</td>\n",
              "      <td>0.847780</td>\n",
              "      <td>0.089426</td>\n",
              "      <td>0.097354</td>\n",
              "      <td>0.234356</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>0.003042</td>\n",
              "      <td>0.003001</td>\n",
              "      <td>0.003813</td>\n",
              "      <td>0.003149</td>\n",
              "      <td>0.010379</td>\n",
              "      <td>0.002838</td>\n",
              "      <td>0.003128</td>\n",
              "      <td>0.004421</td>\n",
              "      <td>0.002669</td>\n",
              "      <td>0.004116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002929</td>\n",
              "      <td>0.003413</td>\n",
              "      <td>0.004079</td>\n",
              "      <td>0.003499</td>\n",
              "      <td>0.003313</td>\n",
              "      <td>0.004202</td>\n",
              "      <td>0.003486</td>\n",
              "      <td>0.004736</td>\n",
              "      <td>0.003979</td>\n",
              "      <td>0.010751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>0.002676</td>\n",
              "      <td>0.603920</td>\n",
              "      <td>0.021843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1302</th>\n",
              "      <td>0.946045</td>\n",
              "      <td>0.004420</td>\n",
              "      <td>0.016068</td>\n",
              "      <td>0.297421</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1284</th>\n",
              "      <td>0.002995</td>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.008353</td>\n",
              "      <td>0.003317</td>\n",
              "      <td>0.003185</td>\n",
              "      <td>0.175251</td>\n",
              "      <td>0.002905</td>\n",
              "      <td>0.257791</td>\n",
              "      <td>0.003889</td>\n",
              "      <td>0.004943</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003411</td>\n",
              "      <td>0.006067</td>\n",
              "      <td>0.011476</td>\n",
              "      <td>0.002852</td>\n",
              "      <td>0.006034</td>\n",
              "      <td>0.005113</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1326</th>\n",
              "      <td>0.005099</td>\n",
              "      <td>0.007573</td>\n",
              "      <td>0.006884</td>\n",
              "      <td>0.003046</td>\n",
              "      <td>0.002712</td>\n",
              "      <td>0.006537</td>\n",
              "      <td>0.008116</td>\n",
              "      <td>0.035238</td>\n",
              "      <td>0.029697</td>\n",
              "      <td>0.002185</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>0.122099</td>\n",
              "      <td>0.004643</td>\n",
              "      <td>0.002830</td>\n",
              "      <td>0.002887</td>\n",
              "      <td>0.003398</td>\n",
              "      <td>0.002690</td>\n",
              "      <td>0.002946</td>\n",
              "      <td>0.004517</td>\n",
              "      <td>0.004198</td>\n",
              "      <td>0.002835</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1378</th>\n",
              "      <td>0.053530</td>\n",
              "      <td>0.034053</td>\n",
              "      <td>0.030367</td>\n",
              "      <td>0.004953</td>\n",
              "      <td>0.041402</td>\n",
              "      <td>0.005340</td>\n",
              "      <td>0.003218</td>\n",
              "      <td>0.973586</td>\n",
              "      <td>0.989915</td>\n",
              "      <td>0.976708</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>0.022138</td>\n",
              "      <td>0.003237</td>\n",
              "      <td>0.824580</td>\n",
              "      <td>0.004466</td>\n",
              "      <td>0.013986</td>\n",
              "      <td>0.002854</td>\n",
              "      <td>0.883635</td>\n",
              "      <td>0.003051</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>0.662720</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1393</th>\n",
              "      <td>0.004592</td>\n",
              "      <td>0.003370</td>\n",
              "      <td>0.004448</td>\n",
              "      <td>0.002831</td>\n",
              "      <td>0.002786</td>\n",
              "      <td>0.003396</td>\n",
              "      <td>0.002975</td>\n",
              "      <td>0.002752</td>\n",
              "      <td>0.010654</td>\n",
              "      <td>0.006144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>0.003462</td>\n",
              "      <td>0.004340</td>\n",
              "      <td>0.003657</td>\n",
              "      <td>0.002716</td>\n",
              "      <td>0.004075</td>\n",
              "      <td>0.002990</td>\n",
              "      <td>0.005523</td>\n",
              "      <td>0.003019</td>\n",
              "      <td>0.037799</td>\n",
              "      <td>0.002814</td>\n",
              "      <td>...</td>\n",
              "      <td>0.730541</td>\n",
              "      <td>0.024383</td>\n",
              "      <td>0.012547</td>\n",
              "      <td>0.042445</td>\n",
              "      <td>0.064836</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>0.008199</td>\n",
              "      <td>0.003847</td>\n",
              "      <td>0.003263</td>\n",
              "      <td>0.075462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1644</th>\n",
              "      <td>0.964090</td>\n",
              "      <td>0.004165</td>\n",
              "      <td>0.073153</td>\n",
              "      <td>0.007030</td>\n",
              "      <td>0.005139</td>\n",
              "      <td>0.007811</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1693</th>\n",
              "      <td>0.006282</td>\n",
              "      <td>0.029984</td>\n",
              "      <td>0.158722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>0.003809</td>\n",
              "      <td>0.009630</td>\n",
              "      <td>0.003317</td>\n",
              "      <td>0.150510</td>\n",
              "      <td>0.712594</td>\n",
              "      <td>0.006008</td>\n",
              "      <td>0.008794</td>\n",
              "      <td>0.002470</td>\n",
              "      <td>0.002604</td>\n",
              "      <td>0.015849</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944</th>\n",
              "      <td>0.002860</td>\n",
              "      <td>0.003094</td>\n",
              "      <td>0.004355</td>\n",
              "      <td>0.004013</td>\n",
              "      <td>0.036935</td>\n",
              "      <td>0.006040</td>\n",
              "      <td>0.005223</td>\n",
              "      <td>0.003938</td>\n",
              "      <td>0.003802</td>\n",
              "      <td>0.003517</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003140</td>\n",
              "      <td>0.004070</td>\n",
              "      <td>0.005370</td>\n",
              "      <td>0.003811</td>\n",
              "      <td>0.002996</td>\n",
              "      <td>0.004794</td>\n",
              "      <td>0.005304</td>\n",
              "      <td>0.009126</td>\n",
              "      <td>0.007353</td>\n",
              "      <td>0.003869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1526</th>\n",
              "      <td>0.007434</td>\n",
              "      <td>0.003950</td>\n",
              "      <td>0.977403</td>\n",
              "      <td>0.004760</td>\n",
              "      <td>0.012159</td>\n",
              "      <td>0.004952</td>\n",
              "      <td>0.002633</td>\n",
              "      <td>0.122099</td>\n",
              "      <td>0.073003</td>\n",
              "      <td>0.010125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004437</td>\n",
              "      <td>0.005656</td>\n",
              "      <td>0.003343</td>\n",
              "      <td>0.002679</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>0.007975</td>\n",
              "      <td>0.005797</td>\n",
              "      <td>0.103736</td>\n",
              "      <td>0.163021</td>\n",
              "      <td>0.163021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>0.967926</td>\n",
              "      <td>0.528449</td>\n",
              "      <td>0.007728</td>\n",
              "      <td>0.017828</td>\n",
              "      <td>0.010350</td>\n",
              "      <td>0.967529</td>\n",
              "      <td>0.960840</td>\n",
              "      <td>0.944907</td>\n",
              "      <td>0.977816</td>\n",
              "      <td>0.005301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>0.002848</td>\n",
              "      <td>0.006324</td>\n",
              "      <td>0.006319</td>\n",
              "      <td>0.005851</td>\n",
              "      <td>0.235387</td>\n",
              "      <td>0.003245</td>\n",
              "      <td>0.005470</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18fdb0a2-5cad-4e04-9bd5-9314a097ca47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18fdb0a2-5cad-4e04-9bd5-9314a097ca47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18fdb0a2-5cad-4e04-9bd5-9314a097ca47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "sent_numeric.sample(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmAZ-dlDDpNZ"
      },
      "outputs": [],
      "source": [
        "sent_numeric.to_csv('/content/drive/My Drive/depressionrnn/sent_numeric_final.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osAOZW_cQXmA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDZVX32MQCpz"
      },
      "outputs": [],
      "source": [
        "input_size = 36 #Always Check\n",
        "output_size = 2\n",
        "hidden_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2jIVT-0P9Db"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size) \n",
        "        #self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        #x = F.sigmoid(self.fc3(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO3yiDlDFs9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0960fc99-7efc-4c83-f9c4-6295b451722b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  unpickler.persistent_load = persistent_load\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=36, out_features=10, bias=True)\n",
              "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "source": [
        "model_para = torch.load('/content/drive/My Drive/depressionrnn/parapred.pt')\n",
        "model_para.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iezia4idTa_S"
      },
      "source": [
        "FINAL WORKING OF THE PROJECT!!!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ic5SIV1oH_8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9733d089-a9a2-4ca2-cda7-d0603ddb342b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your sentiment: i am going crazy\n"
          ]
        }
      ],
      "source": [
        "user_para= input(\"Enter your sentiment: \") #\"please tell me this stupid algorithm works. I am very sad and lonely\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlEnIKXZJAla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58260c61-de56-4794-9a9d-a0296f1c1e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am going crazy\n",
            "[0.6834921836853027]\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = sent_tokenize(user_para)\n",
        "numeric_symptoms_sent_list=[]\n",
        "length= 0\n",
        "for sentence in sent_tokens:\n",
        "  print(sentence)\n",
        "  tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "  indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "  tensor = torch.LongTensor(indexed)\n",
        "  tensor = tensor.unsqueeze(1)\n",
        "  prediction = torch.sigmoid(model(tensor))\n",
        "  numeric_symptoms_sent_list.append(prediction.item())\n",
        "print(numeric_symptoms_sent_list)\n",
        "prediction_score = max(numeric_symptoms_sent_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "devWTdNjO3bD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2158dd07-38d7-483f-c9e5-681c32cb7eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0.6834921836853027\n",
            "mild depression symptoms present\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        }
      ],
      "source": [
        "length = len(numeric_symptoms_sent_list)\n",
        "print(length)\n",
        "if length<36:\n",
        "  for i in range(length,36):\n",
        "    numeric_symptoms_sent_list.append(0.0)   \n",
        "sample = np.array(numeric_symptoms_sent_list)\n",
        "sample_tensor = torch.from_numpy(sample).float()\n",
        "out = model_para(sample_tensor)\n",
        "_,predicted = torch.max(out.data,-1)\n",
        "\n",
        "print(prediction_score)\n",
        "\n",
        "if prediction_score<0.3:\n",
        "  print(\"no depression symptoms present\")\n",
        "elif prediction_score>0.7:\n",
        "  print(\"severe depression symptoms present\")\n",
        "else:\n",
        "  print(\"mild depression symptoms present\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz69VZCjRbAf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sentiment-analysis-rnn-bidirectional",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}